---
format:
    revealjs:
      slide-number: false
      progress: false
      chalkboard: true
      code-overflow: wrap
      theme: [default, custom.scss]
---

```{r setup, include=FALSE}
library(knitr)

opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE,
               out.width = "100%")

library(tidyverse)
library(tinytable)
library(kableExtra)
library(DeclareDesign)
library(tidyr)
library(broom)


# ggplot global options
theme_set(theme_gray(base_size = 20))

```



::: {style="text-align: center"}
## Experiments {.center}

### POLI SCI 210

Introduction to Empirical Methods in Political Science

:::




## Last week

- Surveys and how to make them good

- Importance of random sampling to justify statistical inference via asymptotic properties (CLT)

- **So far:** Mostly about *descriptive statistics*

## This week

- Moving from *statistical inference* to *causal inference*

- Experiments as the *gold standard*

- **Tuesday:** Logic of experimentation

- [**Thursday:**](#thu) Learning from experiments

## Return to counterfactuals

![](fig/weed.png){width=40% fig-align="center"}

::: aside
[medicine.tulane.edu/news/study-tulane-researcher-suggests-marijuana-can-cause-infertility-men](https://medicine.tulane.edu/news/study-tulane-researcher-suggests-marijuana-can-cause-infertility-men)
:::

## Making causal statements

::: incremental
- Why were we using cautious language?

- **Ideal study:** Compare the same man with and without smoking

- **Actual study:** Compare two *different* groups of men
:::

. . .

&nbsp;

::: {.r-stack}
What would allow us to make more confident **causal** claims?
:::

## Causal inference

. . . 

Imagine we want to establish whether a medical **treatment** improves people's lives

. . .

We want to make sure that the treatment *actually* works

. . .

In other words, we want to *attribute* the treatment as the **cause** of health improvement

. . .

Can we just show that people who receive the treatment get better?

. . .

No! we need some kind of **control**

## Potential outcomes framework

. . .

**Ingredients**

. . .

::: incremental
- $D = \{0,1\}$ condition (0: control, 1: treatment)

- $Y(D)$ is the individual **potential outcome**
:::

. . .

$$
Y = \begin{cases}
Y(0) & \text{if} & D = 0 \\
Y(1) & \text{if} & D = 1
\end{cases}
$$

. . .

Switching equation

$$
Y = Y(1) \cdot D + Y(0) \cdot (1 - D)
$$

## Toy example

```{r}
pop = declare_population(
  N = 4,
  female = c(0, 0, 1, 1),
  Y0 = c(0, 0, 0, 1),
  Y1 = c(0, 1, 1, 1)
)

pot = declare_potential_outcomes(Y ~ Y1 * Z + Y0 * (1-Z))

estimand = declare_inquiry(ATE = mean(Y1 - Y0))

assign = declare_assignment(Z = complete_ra(N, m = 2))

reveal = declare_measurement(Y = reveal_outcomes(Y ~ Z))

estimator = declare_estimator(Y ~ Z, inquiry = "ATE")

design_1 = pop + pot + estimand + assign + reveal + estimator
```

```{r}
set.seed(142)

dat = draw_data(design_1)

dat_0 = dat %>% select(ID, Y1, Y0)

colnames(dat_0) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)")

dat_0 %>% kbl(escape = FALSE)
```

. . .

$\tau_i = Y(1) - Y(0)$ is the **individual treatment effect**

&nbsp;

## Toy example

```{r}
dat_1 = dat %>% 
  select(ID, Y1, Y0) %>% 
  mutate(tau = Y1 - Y0)

colnames(dat_1) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)", "\\(\\tau_i\\)")

dat_1 %>% kbl(escape = FALSE)
```

$\tau_i = Y(1) - Y(0)$ is the **individual treatment effect**

&nbsp;

. . .



$\tau = \frac{1}{n} \sum_{i=1}^n \tau_i$ is the  **average treatment effect** (ATE)

## Challenge


```{r}
dat_1 %>% 
  kbl(escape = FALSE)
```


## Challenge

```{r}
dat_1 %>% 
  kbl(escape = FALSE) %>% 
  add_header_above(c(" ", "Unobserved" = 3))
```

. . .

Assign condition $D$ (0: control, 1: treatment)

## Challenge

```{r}
dat_2 = dat %>% 
  select(ID, Y1, Y0, Z, Y) %>% 
  mutate(tau = Y1 - Y0) %>% 
  relocate(tau, .after = "Y0")

colnames(dat_2) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)", "\\(\\tau_i\\)",
                    "\\(D\\)", "\\(Y\\)")

dat_2 %>% 
  kbl(escape = FALSE) %>%
  add_header_above(c(" ", "Unobserved" = 3,  "Observed" = 2)) %>% 
  column_spec(2:4, color = "gray")
```

. . .

To know the ATE we need $(Y(1) - Y(0))$

. . .

But we only observe one at a time for each unit

## Challenge

```{r}
dat_2 %>% 
  kbl(escape = FALSE) %>%
  add_header_above(c(" ", "Unobserved" = 3,  "Observed" = 2)) %>% 
  column_spec(2:4, color = "gray")
```

This is the **FUNDAMENTAL PROBLEM OF CAUSAL INFERENCE**


::: aside
The term comes from: Holland, Paul W. 1986. ["Statistics and Causal Inference."](https://doi.org/10.2307/2289064) *Journal of the American Statistical Association* 81 (396): 945-960
:::

## What can we do?

. . .

We can rewrite the ATE as $\tau = E[\tau_i]$

. . . 

And then expand since $\tau_i = Y(1) - Y(0)$ 

. . .

$$
\tau = E[Y(1) - Y(0)]
$$

## What can we do?

We can rewrite the ATE as $\tau = E[\tau_i]$

And then expand since $\tau_i = Y(1) - Y(0)$ 

$$
\underbrace{\tau = E[Y(1) - Y(0)]}_\text{Average individual treatment effect}
$$

. . .

Which is equivalent to

. . .

$$
\tau = E[Y(1)] - E[Y(0)] 
$$

## What can we do?


We can rewrite the ATE as $\tau = E[\tau_i]$


And then expand since $\tau_i = Y(1) - Y(0)$ 


$$
\underbrace{\tau = E[Y(1) - Y(0)]}_\text{Average individual treatment effect}
$$


Which is equivalent to


$$
\underbrace{\tau = E[Y(1)] - E[Y(0)] }_{\text{Difference in average potential outcomes}}
$$

. . .

::: {style="font-size: 60%;"}
(because the sum of the averages = average of the sums)
:::

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}} 
$$

. . .

But we can only calculate

. . .

$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}} 
$$


But we can only calculate


$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$




## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$

But we can only calculate


$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$

But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]}_\text{Difference in (observed) means between treatment and control groups}
$$

. . .

What would make these two equivalent?

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$


But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) \color{purple}{| D = 1}] - E[Y(0) \color{purple}{| D = 0}]}_\text{Difference in (observed) means between treatment and control groups}
$$


What would make these two equivalent?

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$


But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) \color{purple}{| D = 1}] - E[Y(0) \color{purple}{| D = 0}]}_\text{Difference in (observed) means between treatment and control groups}
$$

We want **treatment assignment** to be **ignorable**


## Random assignment

::: incremental
- If we can claim that units are assigned to conditions $D$ **independently** from potential outcomes

- Then we can claim that $\widehat \tau$ is a *valid* approximation of $\tau$

- So that the *difference in means* is an **unbiased estimator** of the *ATE*

- Random assignment guarantees this **in expectation**
:::

## Implications

If random assignment works:

::: incremental
- No reverse causation

- No selection bias

- No omitted variable bias
:::

. . .

But you can always get unlucky!

## Example

```{r}
declaration = 
  declare_model(N = 100, U = rnorm(N),
                potential_outcomes(Y ~ 0.25 * Z + U)) +
  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_assignment(Z = complete_ra(N, prob = 0.5)) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(Y ~ Z, model = difference_in_means, 
                    inquiry = "ATE")

set.seed(20241108)
experiment = draw_data(declaration) %>% 
  rename(D = Z,
         Y0 = Y_Z_0,
         Y1 = Y_Z_1) %>% 
  select(ID, Y0, Y1, D, Y)
```


```{r}
experiment
```

```{r}
obs = difference_in_means(Y ~ D, data = experiment)
```
::: incremental

- **True ATE:** 0.25

- **Estimate:** `r round(obs$coefficients, 3)` (p = `r round(obs$p.value, 3)`)

:::

## Redo experiment 1,000 times

```{r, cache = TRUE}
set.seed(20250130)
sim_exp = simulate_design(declaration, future.seed = FALSE)
```


```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density")
```

## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE")
```

## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE") +
  geom_vline(xintercept = obs$conf.low,
             linetype = "dotted") +
  geom_vline(xintercept = obs$conf.high,
             linetype = "dotted")
```


## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE") +
  geom_vline(xintercept = obs$conf.low,
             linetype = "dotted") +
  geom_vline(xintercept = obs$conf.high,
             linetype = "dotted")
```

**95% confidence interval:** `r paste("[", round(obs$conf.low, 2), ",", round(obs$conf.high, 2), "]")`

## Types of experiment

- Survey experiments

- Field experiments

- Laboratory experiments

. . .

Depends on *how treatments are delivered*

# Examples

## Tomz and Weeks (2013): "Public Opinion and the Democratic Peace"

::: incremental

- Surveys in the UK ($n = 762$) and US ($n = 1273$)

- April-May 2010

- **Outcome:** Support for military strike

- 2x2x2 survey experiment

:::

::: aside
Tomz, Michael R. and Jessica L.P. Weeks. 2013. ["Public Opinion and the Democratic Peace."](https://doi.org/10.1017/S0003055413000488) *American Political Science Review* 107 (4): 849-865
:::

## Vignette design

. . .

:::: columns

::: {.column width="50%"}
### UK

::: incremental
- **Political regime:** Democracy/not a democracy

- **Military alliances:** Ally/not an ally

- **Military power:** As strong/half as strong

:::

:::

::: {.column width="50%"}

### US

::: incremental

- **Political regime:** Democracy/not a democracy

- **Military alliances:** Ally/not an ally

- **Trade:** High level/not high level

:::

:::

::::

## Results for democracy

![](fig/tomz_weeks_1.png){fig-align="center"}

## Kalla et al (2018): Are You My Mentor?

::: incremental
- Correspondence experiment with $N = 8189$ legislators in the US

- Also known as *audit* experiments

- Send email about fake student seeking advice to become politician

- Cue gender with student's name
:::

::: aside
Kalla, Joshua, Frances Rosenbluth, and Dawn Langan Teele. 2018. ["Are You My Mentor? A Field Experiment on Gender, Ethnicity, and Political Self-Starters."](https://doi.org/10.1086/693984) *Journal of Politics* 80 (1): 337-341
:::

## Sample email

![](fig/kalla_0.png){fig-align="center"}


## Findings {.smaller}

```{r}
kalla = tribble(
  ~Outcome, ~Male, ~Female, ~p,
  "Received reply", 0.25, 0.27, 0.15,
  "Meaningful response", 0.11, 0.13, 0.47,
  "Praised", 0.05, 0.06, 0.17,
  "Offer to help", 0.03, 0.05, 0.09,
  "Warned against running", 0.01, 0.02, 0.14,
  "Substantive advice", 0.07, 0.08, 0.33,
  "Word count (logged)", 1, 1.1, 0.06,
  "Character count", 145, 170, 0.04
)

colnames(kalla) = c("Outcome", "Male Sender", "Female Sender", "p-value")

kalla %>% kbl()
```

. . .

Why not much difference by gender?

::: aside
Adapted from Table 1
:::

## Schnall et al (2008): "Disgust as Embodied Moral Judgment"

::: incremental
- Students at University of Virginia (n = 43, 18 male)

- Offered to participate in study for course credit

- **Outcome:** Moral judgment questions (several scenarios)

- **Treatment:** Extraneous disgust (dirty room)

- **Control:** No disgust (clean room)
:::

::: aside
Schnall, Simone, Jonathan Haidt, Gerald L. Clore, and Alexander H. Jordan. 2008. ["Disgust as Embodied Moral Judgment."](https://doi.org/10.1177/0146167208317771) *Personality and Social Psychology Bulletin* 34 (8): 1023-1153
:::

## Conditions

> On the desk there was a transparent plastic cup with the dried up remnants of a smoothie and a pen that was chewed up. Next to the desk was a trash can overflowing with garbage including greasy pizza boxes and dirty-looking tissues. For the no-disgust condition, the same desk was used, but it was covered up with a clean white tablecloth. A new chair was provided, and none of the disgusting objects were present. A new and unchewed pen was provided for filling out the questionnaires.

## Findings

![](fig/disgust.png){fig-align="center"}

::: aside
*Private body consciousness* is a person's general attention to internal physical states
:::

## Summary

. . .

**Last week:**

- Random **sampling** enables inference from sample to population because of *asymptotic properties* (central limit theorem)

. . .

**This week:**

- Random **assignment** enables causal inference in experiments because of *finite-sample properties* (weak law of large numbers)

. . . 

Can combine both, but often do not need to

::: {style="text-align: center"}
## Experiments {#thu .center}

### POLI SCI 210

Introduction to Empirical Methods in Political Science

:::


## Last time

- Experiments as the **gold standard** for causal inference

- Thanks to random assignment, we can rule out:

1. Reverse causation

2. Selection bias

3. Omitted variable bias

. . .

What exactly can we learn from experiments?

## Learning from experiments

How do you prove that a policy intervention works?

. . .

We want to make statements about *causation*

- **Example:** *Universal income improves political participation*

. . .

To back up those statements, we need to rule out **confounding factors**

- *Those who enroll on universal income programs are already more inclined to participate*
    
. . .

What kind of critique is this?

## Ruling out confounders

We learned that **random assignment** allows us to rule out potential confounders

. . .

We can claim that treatment assignment is **ignorable** or **independent** from other factors

. . .

 **Challenge:** This is only true *in expectation*
 
## A small experiment


```{r}
pop = declare_population(
  N = 4,
  female = c(0, 0, 1, 1),
  Y0 = c(0, 0, 0, 1),
  Y1 = c(0, 1, 1, 1)
)
pot = declare_potential_outcomes(Y ~ Y1 * Z + Y0 * (1-Z))
estimand = declare_inquiry(ATE = mean(Y1 - Y0))
assign = declare_assignment(Z = complete_ra(N, m = 2))
reveal = declare_measurement(Y = reveal_outcomes(Y ~ Z))
estimator = declare_estimator(Y ~ Z, inquiry = "ATE")
design_1 = pop + pot + estimand + assign + reveal + estimator
```


```{r}
set.seed(141)
dat = draw_data(design_1)
dat_0 = dat %>% select(ID, female, Y0, Y1)
colnames(dat_0) = c("ID", "Female", "Y(0)", "Y(1)")
dat_0 %>% kbl()
```

. . .

- $Y(*)$ are the **potential outcomes** under control `(0)`  and treatment `(1)`, respectively

- $Y(*) = 1$ means person's life improves, $Y(*) = 0$ means life stays the same

## A small experiment {visibility="uncounted"}


```{r}
set.seed(141)
dat = draw_data(design_1)
dat_0 = dat %>% select(ID, female, Y0, Y1)
colnames(dat_0) = c("ID", "Female", "Y(0)", "Y(1)")
dat_0 %>% kbl()
```

- We have:

    - One person for which the policy would do nothing
    - Two people for which the policy improves life
    - One person who improves their life either way
    
## Assign treatment at random

```{r}
dat_1 = dat %>% select(ID, female, Y0, Y1, Z)
colnames(dat_1) = c("ID", "Female", "Y(0)", "Y(1)", "Z")
dat_1 %>% kbl() %>% column_spec(3:4, color = "gray")
```

. . .

- We happened to randomly assign the policy to the two women

- We only observe the potential outcomes that corresponds to the treatment status

## Revealing outcomes

```{r}
dat_2 = dat %>% select(ID, female, Y0, Y1, Z, Y)
colnames(dat_2) = c("ID", "Female", "Y(0)", "Y(1)", "Z", "Y obs")
dat_2 %>% kbl() %>% column_spec(3:4, color = "gray")
```

. . .

- The **true** treatment effect is 

$$ATE = E[Y(1)] - E[Y(0)] = 3/4 - 1/4 = 1/2$$

- Which we **cannot observe in the real world**

## Revealing outcomes {visibility="uncounted"}

```{r}
dat_2 = dat %>% select(ID, female, Y0, Y1, Z, Y)
colnames(dat_2) = c("ID", "Female", "Y(0)", "Y(1)", "Z", "Y obs")
dat_2 %>% kbl() %>% column_spec(3:4, color = "gray")
```

- We can **approximate** the ATE with $\widehat{ATE} = 2/2 - 0/2 = 1$

- We are off the mark! What happens if we redo the experiment?

## Redoing the experiment

```{r}
set.seed(142)
redo = draw_data(design_1)
dat_3 = redo %>% select(ID, female, Y0, Y1, Z, Y)
colnames(dat_3) = c("ID", "Female", "Y(0)", "Y(1)", "Z", "Y obs")
dat_3 %>% kbl() %>% column_spec(3:4, color = "gray")
```

. . .

- We still have $ATE = 1/2$

- But now $\widehat{ATE} = 1/2 - 1/2 = 0$

- Off the mark in the opposite direction

## Why does this happen?

```{r}
dat_4 = dat %>% select(ID, female, Y0, Y1, Z, Y)
dat_4$Z2 = dat_3[, 5]
dat_4$Y2 = dat_3[, 6]
colnames(dat_4) = c("ID", "Female", "Y(0)", "Y(1)", "Z", "Y obs", "Z", "Y obs")
dat_4 %>% kbl() %>% add_header_above(c(" " = 4, "Experiment 1" = 2, "Experiment 2" = 2)) %>% 
  column_spec(3:4, color = "gray")
```

. . .

- Perhaps men and women react to treatment differently

- We want results to not depend on whether we assign treatments to men or women

## Why does this happen? {visibility="uncounted"}

- **Experiment 1:** 2/2 women in treatment and 0/2 in control `(imbalanced)`

- **Experiment 2:** 1/2 woman in treatment and 1/2 in control `(balanced)`

. . .

- Does that mean that experiment 2 is free from **random confounding**?


## Redo 1,000 experiments


```{r, fig.pos = "center", cache = TRUE}
set.seed(20220425)
sims = simulate_design(design_1, sims = 1000)
ggplot(sims) +
  aes(x = estimate) +
  geom_vline(xintercept = mean(sims$estimand), linetype = "dashed", size = 2) +
  geom_density(size = 2, color = "#4E2A84") +
  labs(x = "Observed ATEs", y = "Density") +
  annotate("text", x = mean(sims$estimand) + 0.1, y = 1.5, label = "True ATE", 
           size = 6)
```

::: aside
Half of the time we are spot on, half of the time we are wrong in either direction
:::

## What does this mean?

. . .

- Experiments only rule out the role of potential confounders **IN EXPECTATION**

- We can sustain this claim in two ways

. . .

1. **CLT:** With a sufficiently large sample `(But how large is large enough?)`
    
2. **WLLN:** By repeating the same experiment multiple times `(Nobody does this)`

## In practice

::: incremental
- We only know statitiscal properties in our simulations

- Need a lot of domain expertise to attribute ATE to policy

- This involves **explaining why it works**

- First step toward knowing whether it would **work somewhere else**
:::

## Generalization and extrapolation

- **Critique:** Experiments invest in *internal validity* at the expense of *external validity*

. . .

- **Internal validity:** We can `(probabilistically)` attribute effect to policy intervention

- **External validity:** Whether effect *extrapolates* or *generalizes*

. . .

- **Extrapolation:** Whether it works *elsewhere*

- **Generalization:** Whether it works *everywhere*

## Thinking about external validity

<p align="center"><iframe width="900" height="500" src="https://www.youtube.com/embed/9wmvZH5lX_U?si=M_SbCDBTcWHh_elr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>

::: aside
<https://youtu.be/9wmvZH5lX_U?si=pSNn03CKvYLH4SNm>
:::


## External validity concerns

```{r}
concerns = tribble(
  ~Type, ~Concern,
  "Samples", "Does this apply to a different population?",
  "Contexts", "Does this apply in a different setting?",
  "Treatments", "Do they resemble real-world phenomena?",
  "Outcomes", "Do they reflect actual behaviors?"
)

kbl(concerns) %>% 
  column_spec(2, italic = TRUE) %>% 
    row_spec(1:4, color = "white")
```

::: aside
See [Shadish et al (2002)](https://psycnet.apa.org/record/2002-17373-000) and [Egami and Hartmant (2023)](https://doi.org/10.1017/S0003055422000880) for details
:::

## External validity concerns

```{r}
kbl(concerns) %>% 
  column_spec(2, italic = TRUE) %>% 
  row_spec(2:4, color = "white")
```

::: aside
See [Shadish et al (2002)](https://psycnet.apa.org/record/2002-17373-000) and [Egami and Hartmant (2023)](https://doi.org/10.1017/S0003055422000880) for details
:::

## External validity concerns

```{r}
kbl(concerns) %>% 
  column_spec(2, italic = TRUE) %>% 
  row_spec(3:4, color = "white")
```

::: aside
See [Shadish et al (2002)](https://psycnet.apa.org/record/2002-17373-000) and [Egami and Hartmant (2023)](https://doi.org/10.1017/S0003055422000880) for details
:::

## External validity concerns

```{r}
kbl(concerns) %>% 
  column_spec(2, italic = TRUE) %>% 
  row_spec(4, color = "white")
```

::: aside
See [Shadish et al (2002)](https://psycnet.apa.org/record/2002-17373-000) and [Egami and Hartmant (2023)](https://doi.org/10.1017/S0003055422000880) for details
:::

## External validity concerns

```{r}
kbl(concerns) %>% 
  column_spec(2, italic = TRUE)
```

::: aside
See [Shadish et al (2002)](https://psycnet.apa.org/record/2002-17373-000) and [Egami and Hartmant (2023)](https://doi.org/10.1017/S0003055422000880) for details
:::



## Support factors

::: incremental
- **Example:** A house burns down because the television was left on

- Not all houses with TVs left on burn down, but sometimes they do, perhaps because the wiring was poor

- A **support factor** is one part of the **causal pie**

- **Causal pie:** A set of causes that are jointly but not separately sufficient for a contribution to an effect `(INUS causation)`
:::

::: aside
These ideas come from qualitative methods!
:::

    
## Summary

- Experiments help in establishing *cause and effect*

- But do not explain how/why/where

- Need more knowledge to draw definitive conclusions