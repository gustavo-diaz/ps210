---
format:
    revealjs:
      slide-number: false
      progress: false
      chalkboard: true
      code-overflow: wrap
      theme: [default, custom.scss]
---

```{r setup, include=FALSE}
library(knitr)

opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE,
               out.width = "100%")

library(tidyverse)
library(tinytable)
library(kableExtra)
library(DeclareDesign)
library(tidyr)
library(broom)


# ggplot global options
theme_set(theme_gray(base_size = 20))

```



::: {style="text-align: center"}
## Experiments {.center}

### POLI SCI 210

Introduction to Empirical Methods in Political Science

:::


## AI Prompts {background-color="#B6ACD1"}

- (Fundamental proble of) causal inference

- Potential outcomes framework

- Average treatment effect

- "Help me design a [survey/field/laboratory] experiment about X"



## Last week

- Surveys and how to make them good

- Importance of random sampling to justify statistical inference via asymptotic properties (CLT)

- **So far:** Mostly about *descriptive statistics*

## This week

- Moving from *statistical inference* to *causal inference*

- Experiments as the *gold standard*

- **Tuesday:** Logic of experimentation

- [**Thursday:**](#thu) Learning from experiments

## Return to counterfactuals

![](fig/weed.png){width=40% fig-align="center"}

::: aside
[medicine.tulane.edu/news/study-tulane-researcher-suggests-marijuana-can-cause-infertility-men](https://medicine.tulane.edu/news/study-tulane-researcher-suggests-marijuana-can-cause-infertility-men)
:::

## Making causal statements

::: incremental
- Why were we using cautious language?

- **Ideal study:** Compare the same man with and without smoking

- **Actual study:** Compare two *different* groups of men
:::

. . .

&nbsp;

::: {.r-stack}
What would allow us to make more confident **causal** claims?
:::

## Causal inference

. . . 

Imagine we want to establish whether a medical **treatment** improves people's lives

. . .

We want to make sure that the treatment *actually* works

. . .

In other words, we want to *attribute* the treatment as the **cause** of health improvement

. . .

Can we just show that people who receive the treatment get better?

. . .

No! we need some kind of **control**

## Potential outcomes framework

. . .

**Ingredients**

. . .

::: incremental
- $D = \{0,1\}$ condition (0: control, 1: treatment)

- $Y(D)$ is the individual **potential outcome**
:::

. . .

$$
Y = \begin{cases}
Y(0) & \text{if} & D = 0 \\
Y(1) & \text{if} & D = 1
\end{cases}
$$

. . .

Switching equation

$$
Y = Y(1) \cdot D + Y(0) \cdot (1 - D)
$$

## Toy example

```{r}
pop = declare_population(
  N = 4,
  female = c(0, 0, 1, 1),
  Y0 = c(0, 0, 0, 1),
  Y1 = c(0, 1, 1, 1)
)

pot = declare_potential_outcomes(Y ~ Y1 * Z + Y0 * (1-Z))

estimand = declare_inquiry(ATE = mean(Y1 - Y0))

assign = declare_assignment(Z = complete_ra(N, m = 2))

reveal = declare_measurement(Y = reveal_outcomes(Y ~ Z))

estimator = declare_estimator(Y ~ Z, inquiry = "ATE")

design_1 = pop + pot + estimand + assign + reveal + estimator
```

```{r}
set.seed(142)

dat = draw_data(design_1)

dat_0 = dat %>% select(ID, Y1, Y0)

colnames(dat_0) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)")

dat_0 %>% kbl(escape = FALSE)
```

. . .

$\tau_i = Y(1) - Y(0)$ is the **unit-level treatment effect**

&nbsp;

## Toy example

```{r}
dat_1 = dat %>% 
  select(ID, Y1, Y0) %>% 
  mutate(tau = Y1 - Y0)

colnames(dat_1) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)", "\\(\\tau_i\\)")

dat_1 %>% kbl(escape = FALSE)
```

$\tau_i = Y(1) - Y(0)$ is the **unit-level treatment effect**

&nbsp;

. . .



$\tau = \frac{1}{n} \sum_{i=1}^n \tau_i$ is the  **average treatment effect** (ATE)

## Challenge


```{r}
dat_1 %>% 
  kbl(escape = FALSE)
```


## Challenge

```{r}
dat_1 %>% 
  kbl(escape = FALSE) %>% 
  add_header_above(c(" ", "Unobserved" = 3))
```

. . .

Assign condition $D$ (0: control, 1: treatment)

## Challenge

```{r}
dat_2 = dat %>% 
  select(ID, Y1, Y0, Z, Y) %>% 
  mutate(tau = Y1 - Y0) %>% 
  relocate(tau, .after = "Y0")

colnames(dat_2) = c("ID", "\\(Y(1)\\)", "\\(Y(0)\\)", "\\(\\tau_i\\)",
                    "\\(D\\)", "\\(Y\\)")

dat_2 %>% 
  kbl(escape = FALSE) %>%
  add_header_above(c(" ", "Unobserved" = 3,  "Observed" = 2))
```

. . .

To know $\tau$ we need $(Y(1) - Y(0))$

. . .

But we only observe one at a time for each unit

## Challenge

```{r}
dat_2 %>% 
  kbl(escape = FALSE) %>%
  add_header_above(c(" ", "Unobserved" = 3,  "Observed" = 2))
```

This is the **FUNDAMENTAL PROBLEM OF CAUSAL INFERENCE**


::: aside
The term comes from: Holland, Paul W. 1986. ["Statistics and Causal Inference."](https://doi.org/10.2307/2289064) *Journal of the American Statistical Association* 81 (396): 945-960
:::

## What can we do?

. . .

We can rewrite the ATE as $\tau = E[\tau_i]$

. . . 

And then expand since $\tau_i = Y(1) - Y(0)$ 

. . .

$$
\tau = E[Y(1) - Y(0)]
$$

## What can we do?

We can rewrite the ATE as $\tau = E[\tau_i]$

And then expand since $\tau_i = Y(1) - Y(0)$ 

$$
\underbrace{\tau = E[Y(1) - Y(0)]}_\text{Average individual treatment effect}
$$

. . .

Which is equivalent to

. . .

$$
\tau = E[Y(1)] - E[Y(0)] 
$$

## What can we do?


We can rewrite the ATE as $\tau = E[\tau_i]$


And then expand since $\tau_i = Y(1) - Y(0)$ 


$$
\underbrace{\tau = E[Y(1) - Y(0)]}_\text{Average individual treatment effect}
$$


Which is equivalent to


$$
\underbrace{\tau = E[Y(1)] - E[Y(0)] }_{\text{Difference in average potential outcomes}}
$$

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}} 
$$

. . .

But we can only calculate

. . .

$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}} 
$$


But we can only calculate


$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$


## Aside on notation

:::: {.columns}

::: {.column width="50%"}
### Greek

- Letters like $\mu$ denote **estimands** (unobserved quantities of interest)

- A hat $\widehat{\mu}$ denotes **estimators** (rules to calculate a quantity)

:::

::: {.column width="50%"}
### Latin

- Letters like $X$ denote **actual variables** in our data

- A bar $\overline{X}$  denotes an **estimate** calculated from our data

:::

::::

. . .

::: {style="text-align: center"}
$X \rightarrow \overline{X} \rightarrow \widehat{\mu} \xrightarrow{\text{hopefully!}} \mu$
::: 

## Aside on notation

:::: {.columns}

::: {.column width="50%"}
### Greek

- Letters like $\mu$ denote **estimands** (unobserved quantities of interest)

- A hat $\widehat{\mu}$ denotes **estimators** (rules to calculate a quantity)

:::

::: {.column width="50%"}
### Latin

- Letters like $X$ denote **actual variables** in our data

- A bar $\overline{X}$  denotes an **estimate** calculated from our data

:::

::::

::: {style="text-align: center"}
$\text{Data} \rightarrow \text{Estimate} \rightarrow \text{Estimator} \xrightarrow{\text{hopefully!}} \text{Estimand}$
::: 

## Aside on notation

:::: {.columns}

::: {.column width="50%"}
### Greek $\rightarrow$ conceptual

- Letters like $\mu$ denote **estimands** (unobserved quantities of interest)

- A hat $\widehat{\mu}$ denotes **estimators** (rules to calculate a quantity)

:::

::: {.column width="50%"}
### Latin $\rightarrow$ practical

- Letters like $X$ denote **actual variables** in our data

- A bar $\overline{X}$  denotes an **estimate** calculated from our data

:::

::::

::: {style="text-align: center"}
$\text{Data} \rightarrow \text{Estimate} \rightarrow \text{Estimator} \xrightarrow{\text{hopefully!}} \text{Estimand}$
::: 

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$

But we can only calculate


$$
\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]
$$

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$

But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) | D = 1] - E[Y(0) | D = 0]}_\text{Difference in (observed) means between treatment and control groups}
$$

. . .

What would make these two equivalent?

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$


But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) \color{purple}{| D = 1}] - E[Y(0) \color{purple}{| D = 0}]}_\text{Difference in (observed) means between treatment and control groups}
$$


What would make these two equivalent?

## What can we do?

We want to know

$$
\underbrace{\tau = E[Y(1)] - E[Y(0)]}_{\text{Difference in average potential outcomes}}
$$


But we can only calculate


$$
\underbrace{\widehat \tau = E[Y(1) \color{purple}{| D = 1}] - E[Y(0) \color{purple}{| D = 0}]}_\text{Difference in (observed) means between treatment and control groups}
$$

We want **treatment assignment** to be **ignorable**


## Random assignment

::: incremental
- If we can claim that units are assigned to conditions $D$ **independently** from potential outcomes

- Then we can claim that $\widehat \tau$ is a *valid* approximation of $\tau$

- So that the *difference in means* is an **unbiased estimator** of the *ATE*

- Random assignment guarantees this **in expectation**
:::

## Implications

If random assignment works:

::: incremental
- No reverse causation

- No selection bias

- No omitted variable bias
:::

. . .

But you can always get unlucky!

## Example

```{r}
declaration = 
  declare_model(N = 100, U = rnorm(N),
                potential_outcomes(Y ~ 0.25 * Z + U)) +
  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_assignment(Z = complete_ra(N, prob = 0.5)) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(Y ~ Z, model = difference_in_means, 
                    inquiry = "ATE")

set.seed(20241108)
experiment = draw_data(declaration) %>% 
  rename(D = Z,
         Y0 = Y_Z_0,
         Y1 = Y_Z_1) %>% 
  select(ID, Y0, Y1, D, Y)
```


```{r}
experiment
```

```{r}
obs = difference_in_means(Y ~ D, data = experiment)
```
::: incremental

- **True ATE:** 0.25

- **Estimate:** `r round(obs$coefficients, 3)` (p = `r round(obs$p.value, 3)`)

:::

## Redo experiment 1,000 times

```{r, cache = TRUE}
set.seed(20250130)
sim_exp = simulate_design(declaration, future.seed = FALSE)
```


```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density")
```

## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE")
```

## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE") +
  geom_vline(xintercept = obs$conf.low,
             linetype = "dotted") +
  geom_vline(xintercept = obs$conf.high,
             linetype = "dotted")
```


## Redo experiment 1,000 times

```{r}
ggplot(sim_exp) +
  aes(x = estimate) +
  geom_density(linewidth = 2, color = "#4E2A84") +
  labs(x = "Estimated ATE",
       y = "Density") +
  geom_vline(xintercept = 0.25,
             linetype = "dashed") +
  annotate("text", y = -0.01, 
           x = 0.3,
           label = "True ATE") +
  geom_vline(xintercept = obs$conf.low,
             linetype = "dotted") +
  geom_vline(xintercept = obs$conf.high,
             linetype = "dotted")
```

**95% confidence interval:** `r paste("[", round(obs$conf.low, 2), ",", round(obs$conf.high, 2), "]")`

## Types of experiment

- Survey experiments

- Field experiments

- Laboratory experiments

. . .

Depends on *how treatments are delivered*

# Examples

## Tomz and Weeks (2013): "Public Opinion and the Democratic Peace"

::: incremental

- Surveys in the UK ($n = 762$) and US ($n = 1273$)

- April-May 2010

- **Outcome:** Support for military strike

- 2x2x2 survey experiment

:::

::: aside
Tomz, Michael R. and Jessica L.P. Weeks. 2013. ["Public Opinion and the Democratic Peace."](https://doi.org/10.1017/S0003055413000488) *American Political Science Review* 107 (4): 849-865
:::

## Vignette design

. . .

:::: columns

::: {.column width="50%"}
### UK

::: incremental
- **Political regime:** Democracy/not a democracy

- **Military alliances:** Ally/not an ally

- **Military power:** As strong/half as strong

:::

:::

::: {.column width="50%"}

### US

::: incremental

- **Political regime:** Democracy/not a democracy

- **Military alliances:** Ally/not an ally

- **Trade:** High level/not high level

:::

:::

::::

## Results for democracy

![](fig/tomz_weeks_1.png){fig-align="center"}

## Kalla et al (2018): Are You My Mentor?

::: incremental
- Correspondence experiment with $N = 8189$ legislators in the US

- Also known as *audit* experiments

- Send email about fake student seeking advice to become politician

- Cue gender with student's name
:::

::: aside
Kalla, Joshua, Frances Rosenbluth, and Dawn Langan Teele. 2018. ["Are You My Mentor? A Field Experiment on Gender, Ethnicity, and Political Self-Starters."](https://doi.org/10.1086/693984) *Journal of Politics* 80 (1): 337-341
:::

## Sample email

![](fig/kalla_0.png){fig-align="center"}


## Findings {.smaller}

```{r}
kalla = tribble(
  ~Outcome, ~Male, ~Female, ~p,
  "Received reply", 0.25, 0.27, 0.15,
  "Meaningful response", 0.11, 0.13, 0.47,
  "Praised", 0.05, 0.06, 0.17,
  "Offer to help", 0.03, 0.05, 0.09,
  "Warned against running", 0.01, 0.02, 0.14,
  "Substantive advice", 0.07, 0.08, 0.33,
  "Word count (logged)", 1, 1.1, 0.06,
  "Character count", 145, 170, 0.04
)

colnames(kalla) = c("Outcome", "Male Sender", "Female Sender", "p-value")

kalla %>% kbl()
```

. . .

Why not much difference by gender?

::: aside
Adapted from Table 1
:::

## Schnall et al (2008): "Disgust as Embodied Moral Judgment"

::: incremental
- Students at University of Virginia (n = 43, 18 male)

- Offered to participate in study for course credit

- **Outcome:** Moral judgment questions (several scenarios)

- **Treatment:** Extraneous disgust (dirty room)

- **Control:** No disgust (clean room)
:::

::: aside
Schnall, Simone, Jonathan Haidt, Gerald L. Clore, and Alexander H. Jordan. 2008. ["Disgust as Embodied Moral Judgment."](https://doi.org/10.1177/0146167208317771) *Personality and Social Psychology Bulletin* 34 (8): 1023-1153
:::

## Conditions

> On the desk there was a transparent plastic cup with the dried up remnants of a smoothie and a pen that was chewed up. Next to the desk was a trash can overflowing with garbage including greasy pizza boxes and dirty-looking tissues. For the no-disgust condition, the same desk was used, but it was covered up with a clean white tablecloth. A new chair was provided, and none of the disgusting objects were present. A new and unchewed pen was provided for filling out the questionnaires.

## Findings

![](fig/disgust.png){fig-align="center"}

::: aside
*Private body consciousness* is a person's general attention to internal physical states
:::

## Summary

. . .

**Last week:**

- Random **sampling** enables inference from sample to population because of *asymptotic properties* (central limit theorem)

. . .

**This week:**

- Random **assignment** enables causal inference in experiments because of *finite-sample properties* (weak law of large numbers)

. . . 

Can combine both, but often do not need to

::: {style="text-align: center"}
## Experiments {#thu .center}

### POLI SCI 210

Introduction to Empirical Methods in Political Science

:::


